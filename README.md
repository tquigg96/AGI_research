# AGI_research
//This document will continually update. So always check here before changing tasks.

Decisions:
*Build from scratch

Goal:
Essentially we want to combine image recognition with language generation to create a machine that can pass a turing test. If we come to a point where we have to use paid services, we will pivot to money making practices to further fund the ongoing research. When we start producing results I or Alex or both will look into funding options. Use your overall knowledge to mitigate machine costs. Try to reinvent the wheel - try to make your algorithms even better than what is shown to you. Use your knowledge of O notation to create fast and efficient code. If you are new, don't worry. As long as you have a drive to learn you will do well here. Creativity is welcomed and all feedback is welcomed. 

tasks:

CNN:

1. How many layers do we need and what layers do we need?

Known layers:

1. (input)convolution:
2. pooling:
3. activation: Travis Quigg
4. Output Layer:

RNN:

1. What is a RNN?
 A RNN is a neural net geared for language generation. It follows principles in CSCI 119 - context - free grammars possibly but with conditions. A grammar synthesis and a spelling   rule.
 
2. How many layers do we need for a RNN?

VOTING:

voting = undefined

